<!DOCTYPE html>
<html lang="en">
    <style>
        .center{
            margin-left:50%;
            transform: translateX(-50%);
        }
        #video{
            width:100%;
            height:100%;
            object-fit:fill;
            top: 0;
            left: 0;   
        }
        html, body {
            margin: 0;         
            padding: 0;
            height: 100%;  
        }

        .modal{
            display: none; 
            z-index: 1000;
            width: 100%;
            height: 100%;
            position:fixed;
            overflow: auto;
            top:0;
            left:0;
        }
    </style>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>
<body>
    <div>
        <button class="center" id="startBtn">Start</button>
    </div>
    <div id="videoModal" class="modal">
        <video id="video" autoplay playsinline></video>
    </div>


<script>

</script>
<script type="module">
  import * as vision from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest";
  import * as THREE from 'https://cdn.jsdelivr.net/npm/three@0.161.0/build/three.module.js';
  const {
    HandLandmarker,
    FilesetResolver,
    DrawingUtils
  } = vision;

    const SPIN_DISTANCE = 1.0; // threshold distance to start spinning
    const SPIN_SPEED = 0.1;    // rotation speed

  async function start() {
    if(!confirm("Do You Want To Start")){
        return;
    }
    const videoModal = document.getElementById("videoModal");
    const video = document.getElementById("video");

    videoModal.style.display = "flex";
    const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment",width: { ideal: 1920 },  height: { ideal: 1080 }} });
    video.srcObject = stream;
    await video.play();
    const scene = new THREE.Scene();

    const videoTexture = new THREE.VideoTexture(video);
    videoTexture.minFilter = THREE.LinearFilter;
    videoTexture.magFilter = THREE.LinearFilter;
    videoTexture.format = THREE.RGBAFormat;
    scene.background = videoTexture;
    // 3️⃣ Create camera
    const camera = new THREE.PerspectiveCamera(
      70,
      window.innerWidth / window.innerHeight,
      0.1,
      1000
    );
    camera.position.z = 5;
    const axesHelper = new THREE.AxesHelper(2);
    scene.add(axesHelper);
    // 4️⃣ Renderer
    const renderer = new THREE.WebGLRenderer({ alpha: true });
    renderer.setPixelRatio(window.devicePixelRatio);
    renderer.setSize(window.innerWidth, window.innerHeight);
    renderer.domElement.style.position = "absolute";
    renderer.domElement.style.top = "0";
    renderer.domElement.style.left = "0";
    renderer.domElement.style.width = "100%";
    renderer.domElement.style.height = "100%";
    renderer.domElement.style.zIndex = "1001";
    renderer.domElement.style.pointerEvents = "none";
    renderer.domElement.style.objectFit = "fill";
    renderer.domElement.style.display = "flex";

    document.body.appendChild(renderer.domElement);

    const raycaster = new THREE.Raycaster();
    const mouse = new THREE.Vector2();
    let strokePoints = [];
    let currentStroke = null;

    function fingerToRay(finger) {
    mouse.x = (finger.x * 2) - 1;
    mouse.y = -(finger.y * 2) + 1;
    raycaster.setFromCamera(mouse, camera);
    }

function getFinger3DPoint(finger, camera) {
    // Convert normalized screen coords to NDC
    const ndc = new THREE.Vector3(
        (finger.x * 2) - 1,
        -(finger.y * 2) + 1,
        0.5 // z in NDC just for direction
    );

    // Convert to world coordinates along camera ray
    ndc.unproject(camera);

    // Direction from camera
    const dir = ndc.sub(camera.position).normalize();

    // Map MediaPipe z to world distance
    // Adjust min/max depth as needed for your scene
    const depth = THREE.MathUtils.mapLinear(finger.z, -0.4, 0.2, 1, 10);

    return camera.position.clone().add(dir.multiplyScalar(depth));
}



    function makeStroke(points) {
        if (points.length < 2) return;

        const curve = new THREE.CatmullRomCurve3(points);

        const geometry = new THREE.TubeGeometry(curve, 64, 0.03, 8, false);

        const material = new THREE.MeshStandardMaterial({
            color: 0x00ff88,
            emissive: 0x008844
        });

        return new THREE.Mesh(geometry, material);
    }


function addPoint(point) {
    strokePoints.push(point.clone());

    if (strokePoints.length < 2) return;

    // Remove old mesh
    if (currentStroke) {
        scene.remove(currentStroke);
        currentStroke.geometry.dispose();
        currentStroke.material.dispose();
    }

    // Smooth curve through points
    const curve = new THREE.CatmullRomCurve3(strokePoints);

    // Tube geometry gives thickness
    const geometry = new THREE.TubeGeometry(curve, 64, 0.03, 8, false);

    const material = new THREE.MeshStandardMaterial({
        color: 0x00ff88,
        emissive: 0x008844,
        roughness: 0.5,
        metalness: 0.2
    });

    currentStroke = new THREE.Mesh(geometry, material);
    scene.add(currentStroke);
}



    function isIndexFingerOnly(landmarks) {
        const INDEX_TIP = 8;
        const INDEX_PIP = 6;

        const MIDDLE_TIP = 12;
        const MIDDLE_PIP = 10;

        const RING_TIP = 16;
        const RING_PIP = 14;

        const PINKY_TIP = 20;
        const PINKY_PIP = 18;

        const THUMB_TIP = 4;
        const THUMB_IP = 3;

        const indexUp = landmarks[INDEX_TIP].y < landmarks[INDEX_PIP].y;
        const middleDown = landmarks[MIDDLE_TIP].y > landmarks[MIDDLE_PIP].y;
        const ringDown = landmarks[RING_TIP].y > landmarks[RING_PIP].y;
        const pinkyDown = landmarks[PINKY_TIP].y > landmarks[PINKY_PIP].y;

        // Thumb is sideways, so use X axis
        const thumbDown =
            Math.abs(landmarks[THUMB_TIP].x - landmarks[THUMB_IP].x) < 0.03;

        return indexUp && middleDown && ringDown && pinkyDown && thumbDown;
    }

    const fileset = await FilesetResolver.forVisionTasks(
      "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm"
    );

    const handLandmarker = await HandLandmarker.createFromOptions(fileset, {
        baseOptions: {
        modelAssetPath: "https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task"
        },
        runningMode: "VIDEO",
        numHands: 2
    });
    let cube = null; // single cube we reuse
    let previouslyFist = false;
    const loader = new THREE.TextureLoader();
    const texture = loader.load('https://threejs.org/examples/textures/crate.gif');
    const material = new THREE.MeshBasicMaterial({ map: texture });
    const geometry = new THREE.BoxGeometry(1,1,1);

    async function animate() {
        requestAnimationFrame(animate);

    const results = await handLandmarker.detectForVideo(video, performance.now());

    if (!results.landmarks || results.landmarks.length === 0) return;

    const lm = results.landmarks[0];   // first hand
    const finger = lm[8];

    if (isIndexFingerOnly(lm)) {
        const p = getFinger3DPoint(finger,camera);
        if (p) addPoint(p);
    } else {
        strokePoints = [];
        currentStroke = null;
    }



    renderer.render(scene, camera);
}

    animate();

     window.addEventListener('resize', () => {
        camera.aspect = window.innerWidth / window.innerHeight;
        camera.updateProjectionMatrix();
        renderer.setSize(window.innerWidth, window.innerHeight);
    });

  }


  document
  .getElementById("startBtn")
  .addEventListener("click", start);

 
</script>
</body>
</html>